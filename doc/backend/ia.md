ğŸŸ¢ Fase 1 â€” Infraestructura LLM limpia

Objetivo: aprender LLM deployment.

Implementa:

Qwen vÃ­a llama.cpp

Endpoint /classify

ValidaciÃ³n estricta JSON

Fallback a reglas

Batch classification

Aprendizaje:

Docker ML

Prompt engineering

Latencia

GestiÃ³n memoria

DiseÃ±o desacoplado

Esto ya es sÃ³lido.

ğŸŸ¡ Fase 2 â€” Dataset de correcciones (sin entrenar aÃºn)

Cuando el usuario cambie algo:

Guarda en tabla nueva:

classification_feedback
---------------------------------
description
amount
predicted_type
predicted_category
corrected_type
corrected_category
timestamp


TodavÃ­a no entrenas nada.

Solo acumulas datos.

Aprendizaje:

DiseÃ±o de dataset real

IngenierÃ­a de features

PreparaciÃ³n de datos

ğŸ”µ Fase 3 â€” Modelo pequeÃ±o entrenado por ti

Cuando tengas 1000+ ejemplos:

Entrenas:

fastText

scikit-learn (LogisticRegression)

o tiny transformer

Este modelo:

Es especÃ­fico para tus datos

Mucho mÃ¡s rÃ¡pido que LLM

MÃ¡s preciso en tu caso concreto

Arquitectura hÃ­brida profesional:

if modelo_personal_confianza > threshold:
    usar modelo_personal
else:
    usar LLM


Eso ya es arquitectura avanzada.

ğŸ“ QuÃ© aprendes realmente con ese enfoque

LLM deployment

Dataset design

Entrenamiento supervisado

MÃ©tricas (accuracy, precision, recall)

GestiÃ³n de versiones de modelo

Arquitectura hÃ­brida ML

Eso es aprendizaje serio.
